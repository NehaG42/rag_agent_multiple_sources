{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6d58a7-64ce-4a6d-844c-4f0c6a67f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.document_loaders import (\n",
    "    WebBaseLoader, BraveSearchLoader, WikipediaLoader,\n",
    "    PyPDFLoader, Docx2txtLoader, TextLoader, CSVLoader, BSHTMLLoader, OnlinePDFLoader\n",
    ")\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c686e02-e92a-475a-ae5d-055d1129738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990073cb-683b-4baa-9e51-c654b3809490",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')   # required\n",
    "BRAVE_API_KEY = os.getenv(\"BRAVE_SEARCH_API_KEY\")            # required for web RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229796c2-e3b0-4418-b722-24688bd01dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader('https://docs.smith.langchain.com/')\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"FOR LANGSMITH ONLY. If the query mentions LangSmith or docs.smith.langchain.com, \"\n",
    "    \"you MUST use this tool and no other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e900246-3a61-46bd-beef-374de15e2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=800)\n",
    "arxiv = ArxivQueryRun(arxiv_wrapper=arxiv_wrapper)\n",
    "arxiv.description = \"ArXiv tool. Use when the query references arXiv or includes an arXiv ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ade33dc-b7ee-4439-9511-1b15de7c4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikipedia_rag(query: str, top_docs: int = 3) -> str:\n",
    "    try:\n",
    "        wiki_docs = WikipediaLoader(query=query, load_max_docs=top_docs).load()\n",
    "    except Exception as e:\n",
    "        return f\"Failed to load from Wikipedia: {e}\"\n",
    "    if not wiki_docs:\n",
    "        return \"No Wikipedia pages found.\"\n",
    "\n",
    "    chunks = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(wiki_docs)\n",
    "    vdb = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "    rel_docs = vdb.as_retriever(search_kwargs={\"k\": 4}).get_relevant_documents(query)\n",
    "    if not rel_docs:\n",
    "        return \"No relevant passages were found in the fetched Wikipedia pages.\"\n",
    "\n",
    "    out, seen = [], []\n",
    "    for d in rel_docs:\n",
    "        title = d.metadata.get(\"title\") or \"Wikipedia\"\n",
    "        if title not in seen:\n",
    "            seen.append(title)\n",
    "        text = d.page_content.strip().replace(\"\\n\", \" \")\n",
    "        if len(text) > 600:\n",
    "            text = text[:600] + \" ...\"\n",
    "        url = d.metadata.get(\"source\") or d.metadata.get(\"wikipedia_url\") or \"\"\n",
    "        src = f\"{title} — {url}\" if url else title\n",
    "        out.append(f\"- Excerpt: {text}\\n  Source: {src}\")\n",
    "\n",
    "    return (\n",
    "        \"Wikipedia RAG answer (supporting snippets):\\n\"\n",
    "        + \"\\n\".join(out[:4])\n",
    "        + \"\\n\\nPages:\\n\"\n",
    "        + \"\\n\".join(f\"* {t}\" for t in seen[:5])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d204ce1-c8eb-4916-9680-915cba73ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_rag_tool = StructuredTool.from_function(\n",
    "    func=wikipedia_rag,\n",
    "    name=\"wikipedia_rag\",\n",
    "    description=(\n",
    "        \"Wikipedia RAG. Use for definitions, people, events, places, timelines, comparisons, or when quotations are needed. \"\n",
    "        \"Args: query:str, top_docs:int=3\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7e3e31-42e6-40c7-a212-206ff982c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_rag_search(query: str, count: int = 5) -> str:\n",
    "    if not BRAVE_API_KEY:\n",
    "        return \"BRAVE_SEARCH_API_KEY is not set.\"\n",
    "    count = max(1, min(int(count), 10))\n",
    "\n",
    "    serp_docs = BraveSearchLoader(query=query, api_key=BRAVE_API_KEY, search_kwargs={\"count\": count}).load()\n",
    "\n",
    "    links = []\n",
    "    for d in serp_docs:\n",
    "        link = d.metadata.get(\"link\")\n",
    "        if link and link not in links:\n",
    "            links.append(link)\n",
    "    if not links:\n",
    "        return \"No web results found.\"\n",
    "\n",
    "    web_docs = []\n",
    "    for url in links:\n",
    "        try:\n",
    "            # If it looks like a PDF URL, fetch as PDF\n",
    "            if url.lower().endswith(\".pdf\"):\n",
    "                page_docs = OnlinePDFLoader(url).load()\n",
    "            else:\n",
    "                page_docs = WebBaseLoader(url).load()\n",
    "            for pd in page_docs:\n",
    "                pd.metadata[\"source\"] = url\n",
    "            web_docs.extend(page_docs)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not web_docs:\n",
    "        return \"Failed to load content from the top web results.\"\n",
    "\n",
    "    chunks = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=200).split_documents(web_docs)\n",
    "    vdb = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "    rel_docs = vdb.as_retriever(search_kwargs={\"k\": 4}).get_relevant_documents(query)\n",
    "    if not rel_docs:\n",
    "        return \"No relevant passages were found in the crawled pages.\"\n",
    "\n",
    "    out, seen = [], []\n",
    "    for d in rel_docs:\n",
    "        src = d.metadata.get(\"source\") or d.metadata.get(\"link\") or \"unknown\"\n",
    "        if src not in seen:\n",
    "            seen.append(src)\n",
    "        text = d.page_content.strip().replace(\"\\n\", \" \")\n",
    "        if len(text) > 600:\n",
    "            text = text[:600] + \" ...\"\n",
    "        out.append(f\"- Excerpt: {text}\\n  Source: {src}\")\n",
    "\n",
    "    return (\n",
    "        \"Web RAG answer (supporting snippets):\\n\"\n",
    "        + \"\\n\".join(out[:4])\n",
    "        + \"\\n\\nTop sources:\\n\"\n",
    "        + \"\\n\".join(f\"* {s}\" for s in seen[:5])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9492aae-d262-4298-8509-1271cd477f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_rag_tool = StructuredTool.from_function(\n",
    "    func=web_rag_search,\n",
    "    name=\"web_rag_search\",\n",
    "    description=(\n",
    "        \"General web RAG (Brave → top 5 links → scrape → chunk → embed → retrieve). \"\n",
    "        \"Default choice when no user documents apply and it’s not an ArXiv/Wikipedia/LangSmith query. \"\n",
    "        \"Args: query:str, count:int=5\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebf07a13-eaf7-4e00-8c87-b754ff52b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "DOC_VDB = None\n",
    "DOC_CHUNK_COUNT = 0\n",
    "DOC_INDEXED = False\n",
    "DOC_SOURCES = set()\n",
    "\n",
    "# Replace your doc_index signature & body with this:\n",
    "def doc_index(files_csv: str = \"\", chunk_size: int = 800, chunk_overlap: int = 100) -> str:\n",
    "    from langchain_community.document_loaders import TextLoader\n",
    "    paths = [p.strip() for p in (files_csv or \"\").split(\",\") if p.strip()]\n",
    "    if not paths:\n",
    "        return \"ERROR: Provide .txt file path(s) via files_csv.\"\n",
    "    if any(not p.lower().endswith(\".txt\") for p in paths):\n",
    "        return \"ERROR: Only .txt files are supported.\"\n",
    "\n",
    "    docs, loaded = [], []\n",
    "    for p in paths:\n",
    "        try:\n",
    "            try:\n",
    "                docs.extend(TextLoader(p, encoding=\"utf-8\").load())\n",
    "            except Exception:\n",
    "                docs.extend(TextLoader(p, encoding=\"utf-8-sig\").load())\n",
    "            loaded.append(p)\n",
    "        except Exception as e:\n",
    "            return f\"ERROR: Failed to load {p}: {e}\"\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=int(chunk_size), chunk_overlap=int(chunk_overlap))\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    global DOC_VDB, DOC_INDEXED, DOC_CHUNK_COUNT\n",
    "    if DOC_VDB is None:\n",
    "        DOC_VDB = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "    else:\n",
    "        DOC_VDB.add_documents(chunks)\n",
    "    DOC_CHUNK_COUNT = getattr(DOC_VDB, \"index\").ntotal if hasattr(DOC_VDB, \"index\") else len(chunks)\n",
    "    DOC_INDEXED = True\n",
    "    return f\"OK: Indexed {len(chunks)} chunks from {len(loaded)} .txt file(s).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9377f4-dfb5-49a9-a979-88e6ef4ac5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "def doc_rag_search(query: str, k: int = 4) -> str:\n",
    "    if DOC_VDB is None:\n",
    "        return \"No indexed documents. Run doc_index first with files_csv.\"\n",
    "    rel = DOC_VDB.as_retriever(search_kwargs={\"k\": int(k)}).get_relevant_documents(query)\n",
    "    if not rel:\n",
    "        return \"No relevant passages found in the indexed documents.\"\n",
    "    labeled = []\n",
    "    for i, d in enumerate(rel, start=1):\n",
    "        txt = d.page_content.strip().replace(\"\\n\", \" \")\n",
    "        if len(txt) > 1200: txt = txt[:1200] + \" ...\"\n",
    "        src = d.metadata.get(\"source\") or d.metadata.get(\"file_path\") or \"uploaded_document\"\n",
    "        labeled.append(f\"[{i}] {txt}\\n(Source: {src})\")\n",
    "    context = \"\\n\\n\".join(labeled)\n",
    "    try:\n",
    "        _llm = llm\n",
    "    except NameError:\n",
    "        _llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "    prompt_text = (\n",
    "        \"Answer ONLY from the provided document excerpts. \"\n",
    "        \"If the answer isn't there, say you couldn't find it in the uploaded document.\\n\\n\"\n",
    "        f\"Question: {query}\\n\\nExcerpts:\\n{context}\\n\\n\"\n",
    "        \"Answer concisely. Include bracketed citations like [1], [2] matching the excerpts you used.\"\n",
    "    )\n",
    "    return _llm.invoke(prompt_text).content\n",
    "\n",
    "def answer(query: str):\n",
    "    # Force Doc-RAG first if we have an index\n",
    "    if 'DOC_INDEXED' in globals() and DOC_INDEXED:\n",
    "        ans = doc_rag_search(query)\n",
    "        if not ans.startswith((\"No indexed documents\", \"No relevant passages\")):\n",
    "            return ans\n",
    "    # Fallback to your agent (web/Wiki/ArXiv/LangSmith) if docs fail or not indexed\n",
    "    selected = pick_tools(query) if 'pick_tools' in globals() else [web_rag_tool, arxiv, wikipedia_rag_tool, retriever_tool]\n",
    "    ag = create_openai_tools_agent(llm, selected, prompt)\n",
    "    ex = AgentExecutor(agent=ag, tools=selected, verbose=True)\n",
    "    return ex.invoke({\"input\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7f817f8-b60b-4293-ab12-3c6cad94c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index_tool = StructuredTool.from_function(\n",
    "    func=doc_index,\n",
    "    name=\"doc_index\",\n",
    "    description=(\"Ingest user documents into a session vector index. \"\n",
    "                 \"Call this when the user provides local .txt files. \"\n",
    "                 \"Args: files_csv:str (comma-separated .txt paths), \"\n",
    "                 \"chunk_size:int=800, chunk_overlap:int=100\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b051213-7254-4b09-ac28-069f80bb1d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_rag_tool = StructuredTool.from_function(\n",
    "    func=doc_rag_search,\n",
    "    name=\"doc_rag_search\",\n",
    "    description=(\"Query the user's indexed documents (from doc_index). \"\n",
    "                 \"Prefer this when documents are indexed and the question could be answered from them. \"\n",
    "                 \"Args: query:str, k:int=4\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91666d48-cce5-4dba-aa1b-e95e261ccabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wikipedia_rag_tool, arxiv, retriever_tool, web_rag_tool, doc_index_tool, doc_rag_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41cf7e02-6713-4d60-9f6a-34e9f721ffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarunkashyap/Desktop/neha_g_git/rag_agent_multiple_sources/nenv/lib/python3.13/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "base_prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0853a872-8ff2-4ad4-ae4d-6cfedfceb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTING_GUIDE = \"\"\"\n",
    "Tool routing policy (follow strictly, in priority order):\n",
    "1) DOCS (TXT-only): If any documents are uploaded, prefer doc_rag_search for queries. Try to strictly answer from the document.\n",
    "2) LANGSMITH: If the query mentions 'LangSmith' or 'docs.smith.langchain.com' → use langsmith_search ONLY.\n",
    "3) ARXIV / PAPERS: If the query references arXiv (contains 'arxiv'/'arXiv' or an arXiv ID like 1605.08386) or asks \n",
    "about a research paper/preprint → use arxiv.\n",
    "4) WIKIPEDIA RAG: Use for definitions, people/biographies, historical events, places, timelines, comparisons,\n",
    "terminology explanations, or when quotations from Wikipedia are useful.\n",
    "5) WEB RAG (Brave): Default for general or dynamic/time-sensitive queries ('latest', 'today', policies, products, news,\n",
    "releases, prices). Search top 5 links → scrape → chunk → embed → retrieve.\n",
    "\n",
    "Hard rules:\n",
    "- Do NOT answer from prior model knowledge when a tool applies.\n",
    "- If multiple categories match, pick the highest-priority applicable tool above.\n",
    "- If the chosen tool yields no relevant results, fall through to the next tool in priority order.\n",
    "- Documents are TXT-only for document RAG.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91f1467e-865d-4d10-b4b8-133c4b156f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = base_prompt + ChatPromptTemplate.from_messages([(\"system\", ROUTING_GUIDE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e74bbf88-04ad-450b-8b46-72b40a12570e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x105a99e40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x105a99e40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad'), SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"\\nTool routing policy (follow strictly, in priority order):\\n1) DOCS (TXT-only): If any documents are uploaded, prefer doc_rag_search for queries. Try to strictly answer from the document.\\n2) LANGSMITH: If the query mentions 'LangSmith' or 'docs.smith.langchain.com' → use langsmith_search ONLY.\\n3) ARXIV / PAPERS: If the query references arXiv (contains 'arxiv'/'arXiv' or an arXiv ID like 1605.08386) or asks \\nabout a research paper/preprint → use arxiv.\\n4) WIKIPEDIA RAG: Use for definitions, people/biographies, historical events, places, timelines, comparisons,\\nterminology explanations, or when quotations from Wikipedia are useful.\\n5) WEB RAG (Brave): Default for general or dynamic/time-sensitive queries ('latest', 'today', policies, products, news,\\nreleases, prices). Search top 5 links → scrape → chunk → embed → retrieve.\\n\\nHard rules:\\n- Do NOT answer from prior model knowledge when a tool applies.\\n- If multiple categories match, pick the highest-priority applicable tool above.\\n- If the chosen tool yields no relevant results, fall through to the next tool in priority order.\\n- Documents are TXT-only for document RAG.\\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ee27076-721f-4afb-99ad-b4bb15d6e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b266c37-f403-4662-993c-dbb75f6ee6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia_rag` with `{'query': 'Logistic Regression'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mWikipedia RAG answer (supporting snippets):\n",
      "- Excerpt: In statistics, multinomial logistic regression is a classification method that generalizes logistic regression to multiclass problems, i.e. with more than two possible discrete outcomes.  That is, it is a model that is used to predict the probabilities of the different possible outcomes of a categorically distributed dependent variable, given a set of independent variables (which may be real-valued, binary-valued, categorical-valued, etc.). Multinomial logistic regression is known by a variety of other names, including polytomous LR, multiclass LR, softmax regression, multinomial logit (mlogit ...\n",
      "  Source: Multinomial logistic regression — https://en.wikipedia.org/wiki/Multinomial_logistic_regression\n",
      "- Excerpt: The parameters of a logistic regression are most commonly estimated by maximum-likelihood estimation (MLE). This does not have a closed-form expression, unlike linear least squares; see § Model fitting. Logistic regression by MLE plays a similarly basic role for binary or categorical responses as linear regression by ordinary least squares (OLS) plays for scalar responses: it is a simple, well-analyzed baseline model; see § Comparison with linear regression for discussion. The logistic regression as a general statistical model was originally developed and popularized primarily by Joseph Berkso ...\n",
      "  Source: Logistic regression — https://en.wikipedia.org/wiki/Logistic_regression\n",
      "- Excerpt: == Applications ==   === General === Logistic regression is used in various fields, including machine learning, most medical fields, and social sciences. For example, the Trauma and Injury Severity Score (TRISS), which is widely used to predict mortality in injured patients, was originally developed by Boyd et al. using logistic regression.  Many other medical s\n",
      "  Source: Logistic regression — https://en.wikipedia.org/wiki/Logistic_regression\n",
      "- Excerpt: Conditional logistic regression is an extension of logistic regression that allows one to account for stratification and matching. Its main field of application is observational studies and in particular epidemiology. It was devised in 1978 by Norman Breslow, Nicholas Day, Katherine Halvorsen, Ross L. Prentice and C. Sabai. It is the most flexible and general procedure for matched data.\n",
      "  Source: Conditional logistic regression — https://en.wikipedia.org/wiki/Conditional_logistic_regression\n",
      "\n",
      "Pages:\n",
      "* Multinomial logistic regression\n",
      "* Logistic regression\n",
      "* Conditional logistic regression\u001b[0m\u001b[32;1m\u001b[1;3mLogistic regression is a statistical method used for binary classification, where the outcome variable is categorical and typically represents two classes, such as 0 and 1. It models the probability of a certain class or event, such as pass/fail, win/lose, alive/dead, etc., based on one or more predictor variables. The logistic function, also known as the sigmoid function, is used to transform the linear combination of the input variables into a probability value between 0 and 1.\n",
      "\n",
      "Logistic regression is commonly estimated using maximum likelihood estimation (MLE) and is widely used in various fields, including machine learning, medicine, and social sciences. It serves as a fundamental model for binary or categorical responses, similar to how linear regression is used for scalar responses. Extensions of logistic regression, such as multinomial logistic regression, allow for multiclass classification problems with more than two possible discrete outcomes.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response1=executor.invoke({\"input\":\"What is Logistic Regression\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41abc295-3704-45d9-af04-c6f86021e1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'AI agents'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2025-07-02\n",
      "Title: AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing\n",
      "Authors: Yinwang Ren, Yangyang Liu, Tang Ji, Xun Xu\n",
      "Summary: AI agents are autonomous systems designed to perceive, reason, and act within\n",
      "dynamic environments. With the rapid advancements in generative AI (GenAI),\n",
      "large language models (LLMs) and multimodal large language models (MLLMs) have\n",
      "significantly improved AI agents' capabilities in semantic comprehension,\n",
      "complex reasoning, and autonomous decision-making. At the same time, the rise\n",
      "of Agentic AI highlights adaptability and goal-directed autonomy in dynamic and\n",
      "complex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents\n",
      "(MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in\n",
      "information processing, environmental perception, and autonomous\n",
      "decision-making, opening new avenues for smart manufacturing. However, the\n",
      "definitions, capability boundaries, and practical applications of these\n",
      "emerging AI paradigms in smart manufacturing remain unclear. To address this\n",
      "gap, this study systematically reviews the evolution of AI and AI agent\n",
      "technologies, examines the core concepts and technological advancements of\n",
      "LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential\n",
      "applications in and integration into manufacturing, along with the potential\n",
      "challenges they may face.\n",
      "\n",
      "Published: 2025-02-25\n",
      "Title: Responsible AI Agents\n",
      "Authors: Deven R. Desai, Mark O. Riedl\n",
      "Summary: Thanks to advances in large language models, a new type of software agent,\n",
      "the artificial intelligence (AI) agent, has entered the marketplace. Companies\n",
      "such as OpenAI, Google, Microsoft, and Salesforce promise their AI Agents will\n",
      "go from generating passive text to executing tasks. Instead of a travel\n",
      "itinerary, an AI Agent would book all aspects of your trip. Instead of\n",
      "generating text or images for social media post, an AI Agent would post the\n",
      "content across a host of social media outlets. The potential power of AI Agents\n",
      "has fueled legal scholars' fears that AI Agents will enable rogue commerce,\n",
      "human manipulation, rampant defamation, and intellectual property harms. These\n",
      "scholars are calling for regulation before AI Agents cause havoc.\n",
      "  This Article addresses the concerns around AI Agents head on. It shows that\n",
      "core aspects of how one piece of software interacts with another creates ways\n",
      "to discipline AI Agents so that rogue, undesired actions are unlikely, perhaps\n",
      "more so than rules designed to govern human agents. It also develops a way to\n",
      "leverage the computer-science approach to value-alignment to improve a user's\n",
      "ability to take action to prevent or correct AI Agent operations. That approach\n",
      "offers and added benefit of helping AI Agents align with norms around user-AI\n",
      "Agent interactions. These practices will enable desired economic outcomes and\n",
      "mitigate perceived risks. The Article also argues that no matter how much AI\n",
      "Agents seem like human agents, they need not, and should not, be given legal\n",
      "personhood status. In short, humans are responsible for AI Agents' actions, and\n",
      "this Article provides a guide for how humans can build and maintain responsible\n",
      "AI Agents.\n",
      "\n",
      "Published: 2025-06-02\n",
      "Title: Agentic AI and Multiagentic: Are We Reinventing the Wheel?\n",
      "Authors: V. Botti\n",
      "Summary: The terms Agentic AI and Multiagentic AI have recently gained popularity in\n",
      "discussions on generative artificial intelligence, often used to describe\n",
      "autonomous software agents and systems composed of such agents. However, the\n",
      "use of these terms confuses these buzzwords with well-established concepts in\n",
      "AI literature: intelligent agents and multi-agent systems. This article offers\n",
      "a critical analysis of this conceptual misuse. We review the theoretical\n",
      "origins of \"agentic\" in the social sciences (Bandura, 1986) and philosophical\n",
      "notions of intentionality (Dennett, 1971), and then summarise foundational\n",
      "works on intelligent agents and multi-agent systems by Wooldridge, \u001b[0m\u001b[32;1m\u001b[1;3mHere are some of the most recent research papers on AI agents:\n",
      "\n",
      "1. **Title:** AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing\n",
      "   - **Authors:** Yinwang Ren, Yangyang Liu, Tang Ji, Xun Xu\n",
      "   - **Published:** July 2, 2025\n",
      "   - **Summary:** This paper discusses the advancements in AI agents, particularly focusing on large language models (LLMs) and multimodal large language models (MLLMs). It explores the evolution of AI agent technologies, their core concepts, and potential applications in smart manufacturing. The study also addresses the challenges faced by these emerging AI paradigms.\n",
      "\n",
      "2. **Title:** Responsible AI Agents\n",
      "   - **Authors:** Deven R. Desai, Mark O. Riedl\n",
      "   - **Published:** February 25, 2025\n",
      "   - **Summary:** This article examines the potential risks associated with AI agents, such as rogue commerce and human manipulation. It proposes ways to discipline AI agents and align them with user norms to prevent undesired actions. The paper argues against granting legal personhood to AI agents and emphasizes human responsibility for their actions.\n",
      "\n",
      "3. **Title:** Agentic AI and Multiagentic: Are We Reinventing the Wheel?\n",
      "   - **Authors:** V. Botti\n",
      "   - **Published:** June 2, 2025\n",
      "   - **Summary:** The paper critically analyzes the use of terms like \"Agentic AI\" and \"Multiagentic AI,\" which have become popular in discussions about generative AI. It highlights the confusion between these buzzwords and established concepts like intelligent agents and multi-agent systems. The article reviews the theoretical origins and foundational works on these topics.\n",
      "\n",
      "These papers provide insights into the latest developments and discussions in the field of AI agents.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response3=executor.invoke({\"input\":\"What is most recent research paper on AI agents?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6b1c1-55f7-44a2-89cc-17fa67fb38e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2d8f4a9-3c8a-44b5-9b1f-9c7bde25f3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Indexed 51 chunks from 1 .txt file(s).\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `doc_rag_search` with `{'query': 'key prerequisites for deep learning in Python'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mKey prerequisites for deep learning in Python include mastering data science and machine learning techniques such as linear regression and logistic regression, understanding gradient descent, and having undergraduate-level math and programming skills. Familiarity with the Python programming language and the numerical computing library Numpy is also necessary [1], [2], [3].\u001b[0m\u001b[32;1m\u001b[1;3mThe key prerequisites for deep learning in Python, as outlined in the uploaded document, include:\n",
      "\n",
      "1. Mastering data science and machine learning techniques such as linear regression and logistic regression.\n",
      "2. Understanding gradient descent.\n",
      "3. Having undergraduate-level math and programming skills.\n",
      "4. Familiarity with the Python programming language.\n",
      "5. Knowledge of the numerical computing library Numpy.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'From the uploaded document only, what are the key prerequisites for deep learning in Python?',\n",
       " 'output': 'The key prerequisites for deep learning in Python, as outlined in the uploaded document, include:\\n\\n1. Mastering data science and machine learning techniques such as linear regression and logistic regression.\\n2. Understanding gradient descent.\\n3. Having undergraduate-level math and programming skills.\\n4. Familiarity with the Python programming language.\\n5. Knowledge of the numerical computing library Numpy.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Document RAG using the agent on the local TXT\n",
    "# This indexes the specified .txt and queries strictly from it.\n",
    "print(doc_index(files_csv=\"deep-learning-in-python-prerequisites.txt\"))\n",
    "\n",
    "query = (\n",
    "    \"From the uploaded document only, what are the key prerequisites for deep learning in Python?\"\n",
    ")\n",
    "\n",
    "# Ensure executor exists (created earlier); if not, initialize it using existing llm/tools/prompt.\n",
    "try:\n",
    "    executor\n",
    "except NameError:\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "response = executor.invoke({\"input\": query})\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5816859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia_rag` with `{'query': 'Logistic Regression'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mWikipedia RAG answer (supporting snippets):\n",
      "- Excerpt: In statistics, multinomial logistic regression is a classification method that generalizes logistic regression to multiclass problems, i.e. with more than two possible discrete outcomes.  That is, it is a model that is used to predict the probabilities of the different possible outcomes of a categorically distributed dependent variable, given a set of independent variables (which may be real-valued, binary-valued, categorical-valued, etc.). Multinomial logistic regression is known by a variety of other names, including polytomous LR, multiclass LR, softmax regression, multinomial logit (mlogit ...\n",
      "  Source: Multinomial logistic regression — https://en.wikipedia.org/wiki/Multinomial_logistic_regression\n",
      "- Excerpt: The parameters of a logistic regression are most commonly estimated by maximum-likelihood estimation (MLE). This does not have a closed-form expression, unlike linear least squares; see § Model fitting. Logistic regression by MLE plays a similarly basic role for binary or categorical responses as linear regression by ordinary least squares (OLS) plays for scalar responses: it is a simple, well-analyzed baseline model; see § Comparison with linear regression for discussion. The logistic regression as a general statistical model was originally developed and popularized primarily by Joseph Berkso ...\n",
      "  Source: Logistic regression — https://en.wikipedia.org/wiki/Logistic_regression\n",
      "- Excerpt: == Applications ==   === General === Logistic regression is used in various fields, including machine learning, most medical fields, and social sciences. For example, the Trauma and Injury Severity Score (TRISS), which is widely used to predict mortality in injured patients, was originally developed by Boyd et al. using logistic regression.  Many other medical s\n",
      "  Source: Logistic regression — https://en.wikipedia.org/wiki/Logistic_regression\n",
      "- Excerpt: Conditional logistic regression is an extension of logistic regression that allows one to account for stratification and matching. Its main field of application is observational studies and in particular epidemiology. It was devised in 1978 by Norman Breslow, Nicholas Day, Katherine Halvorsen, Ross L. Prentice and C. Sabai. It is the most flexible and general procedure for matched data.\n",
      "  Source: Conditional logistic regression — https://en.wikipedia.org/wiki/Conditional_logistic_regression\n",
      "\n",
      "Pages:\n",
      "* Multinomial logistic regression\n",
      "* Logistic regression\n",
      "* Conditional logistic regression\u001b[0m\u001b[32;1m\u001b[1;3mLogistic regression is a statistical method used for binary classification. It is employed to model the probability of a certain class or event, such as pass/fail, win/lose, alive/dead, etc., based on one or more predictor variables. The logistic regression model is a type of regression analysis that predicts the outcome of a categorical dependent variable based on one or more independent variables. The outcome is usually binary (0 or 1), but logistic regression can also be extended to handle multiclass problems, known as multinomial logistic regression.\n",
      "\n",
      "The parameters of logistic regression are typically estimated using maximum-likelihood estimation (MLE). This method does not have a closed-form expression, unlike linear regression, which uses ordinary least squares. Logistic regression is widely used in various fields, including machine learning, medical research, and social sciences, due to its simplicity and effectiveness in binary classification tasks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response1 = executor.invoke({\"input\":\"What is Logistic Regression\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f31cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
