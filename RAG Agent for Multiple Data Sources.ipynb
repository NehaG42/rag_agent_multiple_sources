{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4705c5af-bc06-479f-be6e-7c96fa26f110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun, BraveSearch\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.document_loaders import WebBaseLoader, BraveSearchLoader, WikipediaLoader, PyPDFLoader, Docx2txtLoader, TextLoader, CSVLoader, BSHTMLLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43102735-7df1-44eb-af11-8faf9a0051fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de255271-4eda-4631-b7a7-eeecd37f631f",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2205f3-5aee-4983-8ebf-f94871a9af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "BRAVE_API_KEY = os.getenv(\"BRAVE_SEARCH_API_KEY\")  # required for web search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f03584-7720-4849-90f5-a25ee36a9543",
   "metadata": {},
   "source": [
    "## Wikipedia (Quick search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae98adff-daa6-4ffa-9d7c-fdf1967ec8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=1000)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd62eaa6-9b57-4822-a241-ba0fd88f7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.description = (\n",
    "    \"Wikipedia quick lookup. Use for short factual questions that need a brief summary. \"\n",
    "    \"Do NOT use for detailed/ambiguous multi-part queries or when quotes/timelines are needed; \"\n",
    "    \"prefer wikipedia_rag in those cases.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ece9d3-735d-4fcd-a4eb-bc8c8b328a19",
   "metadata": {},
   "source": [
    "## LangSmith site Retriever tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed499ae3-9839-40c7-907e-dd1fd16bb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=WebBaseLoader('https://docs.smith.langchain.com/')\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fa48df-5615-468c-a864-645b4b091bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x127e77b60>, search_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating vector DB\n",
    "vectordb=FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4402854b-e3e7-4559-9876-d3e14d633add",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"FOR LANGSMITH ONLY. If the query mentions LangSmith or docs.smith.langchain.com, \"\n",
    "    \"you MUST use this tool and no other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "80cb2e44-c677-401b-97fd-1f793b94297b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7cede7-c08e-49cf-945d-264efdb2184d",
   "metadata": {},
   "source": [
    "## Arxiv Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd218f2-159e-408c-8d1b-db561ab516c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(arxiv_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de714ee-1000-49f7-9161-3b973c5db8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv.description = (\n",
    "    \"ArXiv tool. Use when the query references arXiv or includes an arXiv ID.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ad4a4-a928-47b8-8171-bec6c26677ac",
   "metadata": {},
   "source": [
    "## Wikipedia RAG (deeper context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec804f0c-a4d9-4e9a-964e-6e441c836de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikipedia_rag(query: str, top_docs: int = 3) -> str:\n",
    "    try:\n",
    "        wiki_docs = WikipediaLoader(query=query, load_max_docs=top_docs).load()\n",
    "    except Exception as e:\n",
    "        return f\"Failed to load from Wikipedia: {e}\"\n",
    "\n",
    "    if not wiki_docs:\n",
    "        return \"No Wikipedia pages found.\"\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_documents(wiki_docs)\n",
    "\n",
    "    vdb = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "    rel_docs = vdb.as_retriever(search_kwargs={\"k\": 4}).get_relevant_documents(query)\n",
    "\n",
    "    if not rel_docs:\n",
    "        return \"No relevant passages were found in the fetched Wikipedia pages.\"\n",
    "\n",
    "    out, seen = [], []\n",
    "    for d in rel_docs:\n",
    "        title = d.metadata.get(\"title\") or \"Wikipedia\"\n",
    "        if title not in seen:\n",
    "            seen.append(title)\n",
    "        text = d.page_content.strip().replace(\"\\n\", \" \")\n",
    "        if len(text) > 600:\n",
    "            text = text[:600] + \" ...\"\n",
    "        url = d.metadata.get(\"source\") or d.metadata.get(\"wikipedia_url\") or \"\"\n",
    "        src = f\"{title} — {url}\" if url else title\n",
    "        out.append(f\"- Excerpt: {text}\\n  Source: {src}\")\n",
    "\n",
    "    return (\n",
    "        \"Wikipedia RAG answer (supporting snippets):\\n\"\n",
    "        + \"\\n\".join(out[:4])\n",
    "        + \"\\n\\nPages:\\n\"\n",
    "        + \"\\n\".join(f\"* {t}\" for t in seen[:5])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0921ed22-79b3-493a-a44f-718e9612cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_rag_tool = StructuredTool.from_function(\n",
    "    func=wikipedia_rag,\n",
    "    name=\"wikipedia_rag\",\n",
    "    description=(\n",
    "        \"Deep Wikipedia RAG. Use when the question needs detailed context, comparisons, timelines, or quotations \"\n",
    "        \"from Wikipedia beyond a short summary. Args: query:str, top_docs:int=3\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f36a7-e315-46af-84b1-2d3d3d56cd91",
   "metadata": {},
   "source": [
    "## Web RAG via Brave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d287e73-6cf2-4643-b813-51bbf175b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "brave_search_tool = BraveSearch.from_api_key(api_key=BRAVE_API_KEY, search_kwargs={\"count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaa9b69d-9f10-4baf-911e-4abc7f8edb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_rag_search(query: str, count: int = 5) -> str:\n",
    "    if not BRAVE_API_KEY:\n",
    "        return \"BRAVE_SEARCH_API_KEY is not set.\"\n",
    "    count = max(1, min(int(count), 10))\n",
    "\n",
    "    # 1) Search\n",
    "    serp_docs = BraveSearchLoader(query=query, api_key=BRAVE_API_KEY, search_kwargs={\"count\": count}).load()\n",
    "\n",
    "    # 2) Links\n",
    "    links = []\n",
    "    for d in serp_docs:\n",
    "        link = d.metadata.get(\"link\")\n",
    "        if link and link not in links:\n",
    "            links.append(link)\n",
    "    if not links:\n",
    "        return \"No web results found.\"\n",
    "\n",
    "    # 3) Scrape\n",
    "    web_docs = []\n",
    "    for url in links:\n",
    "        try:\n",
    "            for pd in WebBaseLoader(url).load():\n",
    "                pd.metadata[\"source\"] = url\n",
    "                web_docs.append(pd)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not web_docs:\n",
    "        return \"Failed to load content from the top web results.\"\n",
    "\n",
    "    # 4) Chunk → 5) Embed → 6) Similarity search\n",
    "    chunks = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=200).split_documents(web_docs)\n",
    "    vdb = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "    rel_docs = vdb.as_retriever(search_kwargs={\"k\": 4}).get_relevant_documents(query)\n",
    "\n",
    "    if not rel_docs:\n",
    "        return \"No relevant passages were found in the crawled pages.\"\n",
    "\n",
    "    # 7) Compose short answer with sources\n",
    "    out, seen = [], []\n",
    "    for d in rel_docs:\n",
    "        src = d.metadata.get(\"source\") or d.metadata.get(\"link\") or \"unknown\"\n",
    "        if src not in seen:\n",
    "            seen.append(src)\n",
    "        text = d.page_content.strip().replace(\"\\n\", \" \")\n",
    "        if len(text) > 600:\n",
    "            text = text[:600] + \" ...\"\n",
    "        out.append(f\"- Excerpt: {text}\\n  Source: {src}\")\n",
    "\n",
    "    return (\n",
    "        \"Web RAG answer (supporting snippets):\\n\"\n",
    "        + \"\\n\".join(out[:4])\n",
    "        + \"\\n\\nTop sources:\\n\"\n",
    "        + \"\\n\".join(f\"* {s}\" for s in seen[:5])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52f98337-bfbe-4c39-ae6e-940ada971202",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_rag_tool = StructuredTool.from_function(\n",
    "    func=web_rag_search,\n",
    "    name=\"web_rag_search\",\n",
    "    description=\"General web RAG. Use when the question is NOT about Wikipedia, Arxiv, or LangSmith. Args: query:str, count:int=5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5749f7e1-c916-4d53-8969-57f463c93df4",
   "metadata": {},
   "source": [
    "## Document RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b0d5e00-0df4-47fe-8cb0-ef21f47071c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_VDB = None\n",
    "\n",
    "def doc_index(files_csv: str = \"./NehaGaonkarDataScientist.pdf\", urls_csv: str = \"\", chunk_size: int = 1200, chunk_overlap: int = 200) -> str:\n",
    "    \"\"\"\n",
    "    Ingest user-provided documents into an in-memory FAISS index.\n",
    "    - files_csv: comma-separated local file paths (pdf, docx, txt, md, csv, html)\n",
    "    - urls_csv: comma-separated URLs to fetch and index\n",
    "    \"\"\"\n",
    "    paths = [p.strip() for p in files_csv.split(\",\") if p.strip()]\n",
    "    urls  = [u.strip() for u in urls_csv.split(\",\")  if u.strip()]\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    # Load local files\n",
    "    for p in paths:\n",
    "        try:\n",
    "            lo = None\n",
    "            pl = p.lower()\n",
    "            if pl.endswith(\".pdf\"):\n",
    "                lo = PyPDFLoader(p)\n",
    "            elif pl.endswith(\".docx\") or pl.endswith(\".doc\"):\n",
    "                lo = Docx2txtLoader(p)\n",
    "            elif pl.endswith(\".csv\"):\n",
    "                lo = CSVLoader(p)\n",
    "            elif pl.endswith(\".html\") or pl.endswith(\".htm\"):\n",
    "                lo = BSHTMLLoader(p)\n",
    "            elif pl.endswith(\".txt\") or pl.endswith(\".md\"):\n",
    "                lo = TextLoader(p, encoding=\"utf-8\")\n",
    "            else:\n",
    "                # skip unknown types silently to avoid heavy 'unstructured' dependency\n",
    "                continue\n",
    "            docs.extend(lo.load())\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Load URLs\n",
    "    for url in urls:\n",
    "        try:\n",
    "            page_docs = WebBaseLoader(url).load()\n",
    "            for pd in page_docs:\n",
    "                pd.metadata[\"source\"] = url\n",
    "            docs.extend(page_docs)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not docs:\n",
    "        return \"No documents loaded. Provide valid paths in files_csv or URLs in urls_csv.\"\n",
    "\n",
    "    # Chunk and (create or update) vectorstore\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=int(chunk_size), chunk_overlap=int(chunk_overlap))\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    global DOC_VDB, DOC_CHUNK_COUNT, DOC_INDEXED\n",
    "    if DOC_VDB is None:\n",
    "        DOC_VDB = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "    else:\n",
    "        DOC_VDB.add_documents(chunks)\n",
    "\n",
    "    DOC_CHUNK_COUNT += len(chunks)\n",
    "    DOC_INDEXED = DOC_VDB is not None and DOC_CHUNK_COUNT > 0\n",
    "\n",
    "    return f\"Indexed {len(chunks)} chunks from {len(paths)} file(s) and {len(urls)} URL(s).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3b49ad6-5ae8-4029-8a68-102f9d770946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_rag_search(query: str, k: int = 4) -> str:\n",
    "    \"\"\"\n",
    "    Query the user-provided document corpus previously indexed with doc_index.\n",
    "    \"\"\"\n",
    "    if DOC_VDB is None:\n",
    "        return \"No indexed documents. Run doc_index first with files_csv and/or urls_csv.\"\n",
    "    rel = DOC_VDB.as_retriever(search_kwargs={\"k\": int(k)}).get_relevant_documents(query)\n",
    "    if not rel:\n",
    "        return \"No relevant passages found in the indexed documents.\"\n",
    "\n",
    "    out, seen = [], []\n",
    "    for d in rel:\n",
    "        src = d.metadata.get(\"source\") or d.metadata.get(\"file_path\") or d.metadata.get(\"source_path\") or \"uploaded_document\"\n",
    "        if src not in seen: seen.append(src)\n",
    "        text = d.page_content.strip().replace(\"\\n\", \" \")\n",
    "        if len(text) > 700: text = text[:700] + \" ...\"\n",
    "        out.append(f\"- Excerpt: {text}\\n  Source: {src}\")\n",
    "    return \"Document RAG answer (supporting snippets):\\n\" + \"\\n\".join(out[:4]) + \"\\n\\nSources:\\n\" + \"\\n\".join(f\"* {s}\" for s in seen[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be75a313-f40e-4b30-8d70-84af14f36538",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index_tool = StructuredTool.from_function(\n",
    "    func=doc_index,\n",
    "    name=\"doc_index\",\n",
    "    description=(\"Ingest user documents into a persistent (session) vector index. \"\n",
    "                 \"Use when the user uploads or provides links. \"\n",
    "                 \"Args: files_csv:str (comma-separated file paths), urls_csv:str (comma-separated URLs), \"\n",
    "                 \"chunk_size:int=1200, chunk_overlap:int=200\"),\n",
    ")\n",
    "doc_rag_tool = StructuredTool.from_function(\n",
    "    func=doc_rag_search,\n",
    "    name=\"doc_rag_search\",\n",
    "    description=(\"Query the user's indexed documents (from doc_index). \"\n",
    "                 \"Use for questions that refer to the uploaded/added documents. \"\n",
    "                 \"Args: query:str, k:int=4\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10dedf-f1b7-4e63-b914-bf8edf3bffaf",
   "metadata": {},
   "source": [
    "## Combine All Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48528f3f-e18a-4a9d-9d66-7c1998e2f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assemble tools ---\n",
    "tools = [wiki, wikipedia_rag_tool, arxiv, retriever_tool, web_rag_tool, doc_index_tool, doc_rag_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1dc9b08-17b4-439a-bed9-abefe2eb1bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(description='Wikipedia quick lookup. Use for short factual questions that need a brief summary. Do NOT use for detailed/ambiguous multi-part queries or when quotes/timelines are needed; prefer wikipedia_rag in those cases.', api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/tarunkashyap/Desktop/neha_g_git/rag_agent_multiple_sources/nenv/lib/python3.13/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=1000)),\n",
       " StructuredTool(name='wikipedia_rag', description='Deep Wikipedia RAG. Use when the question needs detailed context, comparisons, timelines, or quotations from Wikipedia beyond a short summary. Args: query:str, top_docs:int=3', args_schema=<class 'langchain_core.utils.pydantic.wikipedia_rag'>, func=<function wikipedia_rag at 0x13067c400>),\n",
       " ArxivQueryRun(description='ArXiv tool. Use when the query references arXiv or includes an arXiv ID.', api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='langsmith_search', description='FOR LANGSMITH ONLY. If the query mentions LangSmith or docs.smith.langchain.com, you MUST use this tool and no other.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x1264f8cc0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x127e77b60>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x1264fa160>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x127e77b60>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " StructuredTool(name='web_rag_search', description='General web RAG. Use when the question is NOT about Wikipedia, Arxiv, or LangSmith. Args: query:str, count:int=5', args_schema=<class 'langchain_core.utils.pydantic.web_rag_search'>, func=<function web_rag_search at 0x13067c680>),\n",
       " StructuredTool(name='doc_index', description='Ingest user documents into a persistent (session) vector index. Use when the user uploads or provides links. Args: files_csv:str (comma-separated file paths), urls_csv:str (comma-separated URLs), chunk_size:int=1200, chunk_overlap:int=200', args_schema=<class 'langchain_core.utils.pydantic.doc_index'>, func=<function doc_index at 0x13067cc20>),\n",
       " StructuredTool(name='doc_rag_search', description=\"Query the user's indexed documents (from doc_index). Use for questions that refer to the uploaded/added documents. Args: query:str, k:int=4\", args_schema=<class 'langchain_core.utils.pydantic.doc_rag_search'>, func=<function doc_rag_search at 0x13067d120>)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81c15a-779e-4962-91b0-62b91b66264f",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "427ad83f-213e-4ec6-bd35-6d5d4afb4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1c298cf-1ebd-4cc6-b782-4686445047a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarunkashyap/Desktop/neha_g_git/rag_agent_multiple_sources/nenv/lib/python3.13/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f37e9c87-9a6d-48f0-8d44-4b6f259946de",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=create_openai_tools_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a3065-dc7c-4210-87ab-07833468bc1e",
   "metadata": {},
   "source": [
    "## Agent Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca30a008-f959-4cb5-ba9f-ac650d580377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10795bba0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10795bba0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1302e01a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1302e2120>, root_client=<openai.OpenAI object at 0x130207c50>, root_async_client=<openai.AsyncOpenAI object at 0x1306d42d0>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'Wikipedia quick lookup. Use for short factual questions that need a brief summary. Do NOT use for detailed/ambiguous multi-part queries or when quotes/timelines are needed; prefer wikipedia_rag in those cases.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia_rag', 'description': 'Deep Wikipedia RAG. Use when the question needs detailed context, comparisons, timelines, or quotations from Wikipedia beyond a short summary. Args: query:str, top_docs:int=3', 'parameters': {'properties': {'query': {'type': 'string'}, 'top_docs': {'default': 3, 'type': 'integer'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'ArXiv tool. Use when the query references arXiv or includes an arXiv ID.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'FOR LANGSMITH ONLY. If the query mentions LangSmith or docs.smith.langchain.com, you MUST use this tool and no other.', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'web_rag_search', 'description': 'General web RAG. Use when the question is NOT about Wikipedia, Arxiv, or LangSmith. Args: query:str, count:int=5', 'parameters': {'properties': {'query': {'type': 'string'}, 'count': {'default': 5, 'type': 'integer'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'doc_index', 'description': 'Ingest user documents into a persistent (session) vector index. Use when the user uploads or provides links. Args: files_csv:str (comma-separated file paths), urls_csv:str (comma-separated URLs), chunk_size:int=1200, chunk_overlap:int=200', 'parameters': {'properties': {'files_csv': {'default': './NehaGaonkarDataScientist.pdf', 'type': 'string'}, 'urls_csv': {'default': '', 'type': 'string'}, 'chunk_size': {'default': 1200, 'type': 'integer'}, 'chunk_overlap': {'default': 200, 'type': 'integer'}}, 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'doc_rag_search', 'description': \"Query the user's indexed documents (from doc_index). Use for questions that refer to the uploaded/added documents. Args: query:str, k:int=4\", 'parameters': {'properties': {'query': {'type': 'string'}, 'k': {'default': 4, 'type': 'integer'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(description='Wikipedia quick lookup. Use for short factual questions that need a brief summary. Do NOT use for detailed/ambiguous multi-part queries or when quotes/timelines are needed; prefer wikipedia_rag in those cases.', api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/tarunkashyap/Desktop/neha_g_git/rag_agent_multiple_sources/nenv/lib/python3.13/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=1000)), StructuredTool(name='wikipedia_rag', description='Deep Wikipedia RAG. Use when the question needs detailed context, comparisons, timelines, or quotations from Wikipedia beyond a short summary. Args: query:str, top_docs:int=3', args_schema=<class 'langchain_core.utils.pydantic.wikipedia_rag'>, func=<function wikipedia_rag at 0x13067c400>), ArxivQueryRun(description='ArXiv tool. Use when the query references arXiv or includes an arXiv ID.', api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='langsmith_search', description='FOR LANGSMITH ONLY. If the query mentions LangSmith or docs.smith.langchain.com, you MUST use this tool and no other.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x1264f8cc0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x127e77b60>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x1264fa160>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x127e77b60>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')), StructuredTool(name='web_rag_search', description='General web RAG. Use when the question is NOT about Wikipedia, Arxiv, or LangSmith. Args: query:str, count:int=5', args_schema=<class 'langchain_core.utils.pydantic.web_rag_search'>, func=<function web_rag_search at 0x13067c680>), StructuredTool(name='doc_index', description='Ingest user documents into a persistent (session) vector index. Use when the user uploads or provides links. Args: files_csv:str (comma-separated file paths), urls_csv:str (comma-separated URLs), chunk_size:int=1200, chunk_overlap:int=200', args_schema=<class 'langchain_core.utils.pydantic.doc_index'>, func=<function doc_index at 0x13067cc20>), StructuredTool(name='doc_rag_search', description=\"Query the user's indexed documents (from doc_index). Use for questions that refer to the uploaded/added documents. Args: query:str, k:int=4\", args_schema=<class 'langchain_core.utils.pydantic.doc_rag_search'>, func=<function doc_rag_search at 0x13067d120>)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "710f845b-46ac-4a3d-b72c-2c63a0737cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pick_tools(q: str):\n",
    "#     ql = q.lower()\n",
    "#     if \"langsmith\" in ql or \"docs.smith.langchain.com\" in ql:\n",
    "#         return [retriever_tool]\n",
    "#     if \"arxiv\" in ql or re.search(r\"\\b\\d{4}\\.\\d{5}\\b\", ql):\n",
    "#         return [arxiv]\n",
    "#     # quick wiki signals\n",
    "#     if any(w in ql for w in [\"who is\", \"who was\", \"when was\", \"where is\", \"capital of\", \"definition of\"]):\n",
    "#         return [wiki, wikipedia_rag_tool]\n",
    "#     # default to web\n",
    "#     return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b294eb0-fd18-40e1-aeab-19e503148981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `doc_rag_search` with `{'query': \"Neha's experience\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo indexed documents. Run doc_index first with files_csv and/or urls_csv.\u001b[0m\u001b[32;1m\u001b[1;3mIt seems that I don't have any documents indexed that contain information about Neha's experience. If you have a document or a resume for Neha, you can upload it, and I can help extract the relevant information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response1=agent_executor.invoke({\"input\":\"List experience of Neha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2fbd177-1a13-420a-b4e3-043b23d2427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1605.08386'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPublished: 2016-05-26\n",
      "Title: Heat-bath random walks with Markov bases\n",
      "Authors: Caprice Stanley, Tobias Windisch\n",
      "Summary: Graphs on lattice points are studied whose edges come from a finite set of\n",
      "allowed moves of arbitrary length. We show that the diameter of these graphs on\n",
      "fibers of a fixed integer matrix can be bounded from above by a constant. We\n",
      "then study the mixing behaviour of heat-bath random walks on these graphs. We\n",
      "also state explicit conditions on the set of moves so that the heat-bath random\n",
      "walk, a generalization of the Glauber dynamics, is an expander in fixed\n",
      "dimension.\u001b[0m\u001b[32;1m\u001b[1;3mThe paper titled \"Heat-bath random walks with Markov bases\" by Caprice Stanley and Tobias Windisch, published on May 26, 2016, studies graphs on lattice points where the edges are defined by a finite set of allowed moves of arbitrary length. The authors demonstrate that the diameter of these graphs on fibers of a fixed integer matrix can be bounded by a constant. They also explore the mixing behavior of heat-bath random walks on these graphs and provide explicit conditions on the set of moves to ensure that the heat-bath random walk, a generalization of the Glauber dynamics, is an expander in fixed dimension.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response2=agent_executor.invoke({\"input\":\"What's the paper 1605.08386 about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e41e7b8d-954a-46e5-a746-d600bca6b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'British king who established the Church of England'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Charles II of England\n",
      "Summary: Charles II (29 May 1630 – 6 February 1685) was King of Scotland from 1649 until 1651 and King of England, Scotland, and Ireland from the 1660 Restoration of the monarchy until his death in 1685.\n",
      "Charles II was the eldest surviving child of Charles I of England, Scotland and Ireland and Henrietta Maria of France. After Charles I's execution at Whitehall on 30 January 1649, at the climax of the English Civil War, the Parliament of Scotland proclaimed Charles II king on 5 February 1649. However, England entered the period known as the English Interregnum or the English Commonwealth with a republican government eventually led by Oliver Cromwell. Cromwell defeated Charles II at the Battle of Worcester on 3 September 1651, and Charles fled to mainland Europe. Cromwell became Lord Protector of England, Scotland and Ireland. Charles spent the next nine years in exile in France, the Dutch Republic and the Spanish Netherlands. A political crisis after Cromwel\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Henry VIII Church of England'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Henry VIII\n",
      "Summary: Henry VIII (28 June 1491 – 28 January 1547) was King of England from 22 April 1509 until his death in 1547. Henry is known for his six marriages and his efforts to have his first marriage (to Catherine of Aragon) annulled. His disagreement with Pope Clement VII about such an annulment led Henry to initiate the English Reformation, separating the Church of England from papal authority. He appointed himself Supreme Head of the Church of England and dissolved convents and monasteries, for which he was excommunicated by the pope.\n",
      "Born in Greenwich, Henry brought radical changes to the Constitution of England, expanding royal power and ushering in the theory of the divine right of kings in opposition to papal supremacy. He frequently used charges of treason and heresy to quell dissent, and those accused were often executed without a formal trial using bills of attainder. He achieved many of his political aims through his chief ministers, some of whom were banished \u001b[0m\u001b[32;1m\u001b[1;3mThe British king who established the Church of England was King Henry VIII. He initiated the English Reformation, which led to the separation of the Church of England from papal authority, around the year 1534.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response3=agent_executor.invoke({\"input\":\"Who was the british king who established the church of England and in what year?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a1a5685-5c04-4d27-be83-8e29a02e5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'British king who established the Church of England'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Charles II of England\n",
      "Summary: Charles II (29 May 1630 – 6 February 1685) was King of Scotland from 1649 until 1651 and King of England, Scotland, and Ireland from the 1660 Restoration of the monarchy until his death in 1685.\n",
      "Charles II was the eldest surviving child of Charles I of England, Scotland and Ireland and Henrietta Maria of France. After Charles I's execution at Whitehall on 30 January 1649, at the climax of the English Civil War, the Parliament of Scotland proclaimed Charles II king on 5 February 1649. However, England entered the period known as the English Interregnum or the English Commonwealth with a republican government eventually led by Oliver Cromwell. Cromwell defeated Charles II at the Battle of Worcester on 3 September 1651, and Charles fled to mainland Europe. Cromwell became Lord Protector of England, Scotland and Ireland. Charles spent the next nine years in exile in France, the Dutch Republic and the Spanish Netherlands. A political crisis after Cromwel\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia_rag` with `{'query': 'British king who established the Church of England and his marriage role', 'top_docs': 3}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/1frb69z52qjck_t8hrk9lt2w0000gn/T/ipykernel_49523/3102755797.py:14: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  rel_docs = vdb.as_retriever(search_kwargs={\"k\": 4}).get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mWikipedia RAG answer (supporting snippets):\n",
      "- Excerpt: In 1534, the Church of England renounced the authority of the Papacy under the direction of King Henry VIII, beginning the English Reformation. The guiding theologian that shaped Anglican doctrine was the Reformer Thomas Cranmer, who developed the Church of England's liturgical text, the Book of Common Prayer. Papal authority was briefly restored under Mary I, before her successor Elizabeth I renewed the breach. The Elizabethan Settlement (implemented 1559–1563) concluded the English Reformation, charting a course for the English church to describe itself as a via media between two branches of ...\n",
      "  Source: Church of England — https://en.wikipedia.org/wiki/Church_of_England\n",
      "- Excerpt: The Church of England (C of E) is the established Christian church in England and the Crown Dependencies. It was the initial church of the Anglican tradition. The Church traces its history to the Christian hierarchy recorded as existing in the Roman province of Britain by the 3rd century and to the 6th-century Gregorian mission to Kent led by Augustine of Canterbury. Its members are called Anglicans.\n",
      "  Source: Church of England — https://en.wikipedia.org/wiki/Church_of_England\n",
      "- Excerpt: Since the English Reformation, the Church of England has used the English language in the liturgy. As a broad church, the Church of England contains several doctrinal strands: the main traditions are known as Anglo-Catholic, high church, central church, and low church, the last producing a growing evangelical wing that includes Reformed Anglicanism, with a smaller number of Arminian Anglicans. Tensions between theological conservatives and liberals find expression in debates over the ordination of women and same-sex marriage. The British monarch (currently Charles III) is the supreme governor  ...\n",
      "  Source: Church of England — https://en.wikipedia.org/wiki/Church_of_England\n",
      "- Excerpt: The British monarchy traces its origins from the petty kingdoms of Anglo-Saxon England and early medieval Scotland, which had consolidated into the separate kingdoms of England and Scotland by the 10th century. England was conquered by the Normans in 1066, after which Wales also gradually came under the control of Anglo-Normans. The process was completed in the 13th century when the Principality of Wales became a client state of the English kingdom. The Anglo-Normans also established the Lordship of Ireland. Meanwhile, Magna Carta began the process of reducing the English monarch's political p ...\n",
      "  Source: Monarchy of the United Kingdom — https://en.wikipedia.org/wiki/Monarchy_of_the_United_Kingdom\n",
      "\n",
      "Pages:\n",
      "* Church of England\n",
      "* Monarchy of the United Kingdom\u001b[0m\u001b[32;1m\u001b[1;3mThe British king who established the Church of England was King Henry VIII. His decision to establish the Church of England was significantly influenced by his marriage situation. Henry VIII sought to annul his marriage to Catherine of Aragon because she had not borne him a male heir. However, the Pope refused to grant the annulment. In response, Henry VIII broke away from the Roman Catholic Church and established the Church of England in 1534, with himself as the Supreme Head. This allowed him to annul his marriage and marry Anne Boleyn, marking the beginning of the English Reformation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response4=agent_executor.invoke({\"input\":\"Who was the british king who established the church of England and what was the role of his marriage in his decisiopn?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c20a7e87-32b4-4731-aa11-795d8c6ff146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_rag_search` with `{'query': 'Charlie Kirk shooter identified', 'count': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mWeb RAG answer (supporting snippets):\n",
      "- Excerpt: Charlie Kirk shooting suspect 'was living with transgender partner who handed over texts about assassination plot to the police'By CAROLINE GRAHAM  Published:  23:58, 13 September 2025   |  Updated:  11:49, 14 September 2025                   e-mail        915 shares     3.9k View  comments\n",
      "  Source: https://www.dailymail.co.uk/news/article-15096005/Charlie-Kirk-shooting-suspect-living-transgender-partner-texts-assassination-plot-police.html\n",
      "- Excerpt: Charlie Kirk Shooting Updates: Family Member Alerted Officials to Suspect - The New York Times\n",
      "  Source: https://www.nytimes.com/live/2025/09/12/us/charlie-kirk-news-suspect\n",
      "- Excerpt: Charlie Kirk shooting suspect 'was living with transgender partner who handed over texts about assassination plot to the police' | Daily Mail Online                                                                                                             Home     News     Royals     U.S.     Sport     TV     Showbiz     Femail     Health     Science     Money     Travel     Podcasts     Buyline        Latest Headlines                                             Australia                                                                                   Video                                    ...\n",
      "  Source: https://www.dailymail.co.uk/news/article-15096005/Charlie-Kirk-shooting-suspect-living-transgender-partner-texts-assassination-plot-police.html\n",
      "- Excerpt: Charlie Kirk Shooting Suspect Identified as 22-Year-Old Utah Man | WIREDSkip to main contentMenuSECURITYPOLITICSTHE BIG STORYBUSINESSSCIENCECULTUREREVIEWSMenuAccountAccountNewslettersSecurityPoliticsThe Big StoryBusinessScienceCultureReviewsChevronMoreExpandThe Big InterviewMagazineThe New Era of Business TravelEventsWIRED InsiderWIRED ConsultingNewslettersPodcastsVideoMerchSearchSearchSign InSign InBy Dell CameronPoliticsSep 12, 2025 10:36 AMCharlie Kirk Shooting Suspect Identified as 22-Year-Old Utah ManAuthorities have named Tyler Robinson as a suspect in the murder of right-wing influencer ...\n",
      "  Source: https://www.wired.com/story/charlie-kirk-shooting-suspect-identified-as-22-year-old-utah-man-tyler-robinson/\n",
      "\n",
      "Top sources:\n",
      "* https://www.dailymail.co.uk/news/article-15096005/Charlie-Kirk-shooting-suspect-living-transgender-partner-texts-assassination-plot-police.html\n",
      "* https://www.nytimes.com/live/2025/09/12/us/charlie-kirk-news-suspect\n",
      "* https://www.wired.com/story/charlie-kirk-shooting-suspect-identified-as-22-year-old-utah-man-tyler-robinson/\u001b[0m\u001b[32;1m\u001b[1;3mThe person identified as the shooter of Charlie Kirk is Tyler Robinson, a 22-year-old man from Utah.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response5 = agent_executor.invoke({\"input\":\"Who is the person identified as the shooter of Charlie Kirk?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a879d30-530f-42db-8158-c7d81c633a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_rag_search` with `{'query': 'Trump tariff on India 2023', 'count': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mWeb RAG answer (supporting snippets):\n",
      "- Excerpt: Kin Cheung/WPA/Pool/Getty Images     Trump’s Tariffs and India’s Economic Future  Aug 25, 2025   Ajay Shah     US President Donald Trump’s new tariffs on India will likely cause some immediate economic damage. But the greater risk is that they will prompt the Indian government to turn inward, when it would be better off seeking new international partners and reaffirming its commitment to the globalized economy that has served it so well.\n",
      "  Source: https://www.project-syndicate.org/onpoint/what-trump-s-tariffs-mean-for-india\n",
      "- Excerpt: SportHomeNewsSportBusinessInnovationCultureArtsTravelEarthAudioVideoLiveWeatherNewslettersTrump's 50% tariff on India kicks in as Modi urges self-reliance27 August 2025ShareSaveNikhil InamdarBBC News, MumbaiShareSaveBloomberg via Getty ImagesModi has urged small shop owners and businesses to put up \"Made in India\" boards outside their storesUS tariffs of 50% on goods from India took effect on Wednesday as Donald Trump sought to punish Delhi for buying Russian oil and weapons.The tariffs – among the highest in the world – include a 25% penalty for transactions with Russia that are a key source  ...\n",
      "  Source: https://www.bbc.com/news/articles/c5ykznn158qo\n",
      "- Excerpt: US President Donald Trump’s decision to impose a 50% tariff on imports of Indian goods will have severe effects on India’s economy. The United States imported $87.3 billion worth of Indian goods in 2024, accounting for about 18% of India’s total exports, and economists predict that the tariffs could increase India’s trade deficit, threaten jobs, and shave 0.5 percentage points off GDP growth this year. But, according to Ajay Shah, Co-Founder of XKDR Forum, “several factors” – from India’s diverse trade relationships to its robust services exports – will mitigate the immediate economic impact o ...\n",
      "  Source: https://www.project-syndicate.org/onpoint/what-trump-s-tariffs-mean-for-india\n",
      "- Excerpt: Donald Trump's 50% tariff on India kicks in as PM Modi urges self-relianceSkip to contentBritish Broadcasting CorporationHomeNewsSportBusinessInnovationCultureArtsTravelEarthAudioVideoLiveHomeNewsIsrael-Gaza WarWar in UkraineUS & CanadaUKUK PoliticsEnglandN. IrelandN. Ireland PoliticsScotlandScotland PoliticsWalesWales PoliticsAfricaAsiaChinaIndiaAustraliaEuropeLatin AmericaMiddle EastIn PicturesBBC InDepthBBC VerifySportBusinessExecutive LoungeTechnology of BusinessFuture of BusinessInnovationTechnologyScience & HealthArtificial IntelligenceAI v the MindCultureFilm & TVMusicArt & DesignStyleB ...\n",
      "  Source: https://www.bbc.com/news/articles/c5ykznn158qo\n",
      "\n",
      "Top sources:\n",
      "* https://www.project-syndicate.org/onpoint/what-trump-s-tariffs-mean-for-india\n",
      "* https://www.bbc.com/news/articles/c5ykznn158qo\u001b[0m\u001b[32;1m\u001b[1;3mDonald Trump has imposed a 50% tariff on goods imported from India. This tariff is among the highest in the world and includes a 25% penalty for transactions with Russia. The tariffs are part of measures to punish India for buying Russian oil and weapons. These tariffs are expected to have significant economic impacts on India, potentially increasing the trade deficit and affecting GDP growth.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response6 = agent_executor.invoke({\"input\":\"How much tariff has Trump levied on India?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5afee98d-8360-4956-ad51-d1b457781c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWhy do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response7 = agent_executor.invoke({\"input\":\"Tell me a programming joke\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c364a57-6a86-44d8-9e3e-c569c6cab075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_rag_search` with `{'query': 'latest updates from NASA on the possibility of life on Mars', 'count': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mWeb RAG answer (supporting snippets):\n",
      "- Excerpt: NASA Rover Findings ‘Could Be the Clearest Sign of Life’ on Mars - The New York Times\n",
      "  Source: https://www.nytimes.com/2025/09/10/science/mars-rock-nasa-perserverance.html\n",
      "- Excerpt: See all topics            Facebook      Tweet      Email        Link                 Link Copied!                                              Follow                                  Scientists believe intriguing leopard spots on a rock sampled by the Perseverance rover on Mars last year may have potentially been made by ancient life, NASA announced Wednesday. The team has also published a peer-reviewed paper in the journal Nature about the new analysis, though they say further study is needed.                   “After a year of review, they have come back and they said, listen, we can’t find  ...\n",
      "  Source: https://www.cnn.com/2025/09/10/science/nasa-mars-sapphire-falls-rock-sample\n",
      "- Excerpt: In Tiny Specks, a Possible Sign of Life on Mars. Order Reprints | Today’s Paper | SubscribeSee more on: National Aeronautics and Space Administration, Nature (Journal)Read 49 CommentsShare full article49Related ContentAdvertisementSKIP ADVERTISEMENTSite IndexSite Information Navigation© 2025 The New York Times CompanyNYTCoContact UsAccessibilityWork with usAdvertiseT Brand StudioYour Ad ChoicesPrivacy PolicyTerms of ServiceTerms of SaleSite MapCanadaInternationalHelpSubscriptionsManage Privacy Preferences\n",
      "  Source: https://www.nytimes.com/2025/09/10/science/mars-rock-nasa-perserverance.html\n",
      "- Excerpt: Skip to contentSkip to site indexScience Today’s PaperScience|In a Rock on Mars, NASA Sees ‘Clearest Sign of Life’ So Farhttps://www.nytimes.com/2025/09/10/science/mars-rock-nasa-perserverance.htmlShare full article49AdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTIn a Rock on Mars, NASA Sees ‘Clearest Sign of Life’ So FarThe agency’s scientists are still not saying they found fossils of Martian microbes, but analysis of the specimen collected by the Perseverance rover raises that possibility.Listen to this article · 6:54 min Learn moreShare full article49NASA’s Perseverance Mars  ...\n",
      "  Source: https://www.nytimes.com/2025/09/10/science/mars-rock-nasa-perserverance.html\n",
      "\n",
      "Top sources:\n",
      "* https://www.nytimes.com/2025/09/10/science/mars-rock-nasa-perserverance.html\n",
      "* https://www.cnn.com/2025/09/10/science/nasa-mars-sapphire-falls-rock-sample\u001b[0m\u001b[32;1m\u001b[1;3mRecent updates from NASA suggest that the Perseverance rover has made intriguing discoveries on Mars that could be the clearest signs of ancient life so far. Scientists have found leopard spots on a rock sampled by the rover, which may have been made by ancient life. This finding has been published in a peer-reviewed paper in the journal Nature, although further study is needed to confirm these results. The analysis of the specimen collected by Perseverance raises the possibility of Martian microbes, but NASA scientists are not yet claiming to have found fossils of such life forms. \n",
      "\n",
      "For more detailed information, you can read the full articles on [The New York Times](https://www.nytimes.com/2025/09/10/science/mars-rock-nasa-perserverance.html) and [CNN](https://www.cnn.com/2025/09/10/science/nasa-mars-sapphire-falls-rock-sample).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response9 = agent_executor.invoke({\"input\":\"What are the latest updates from NASA on the possibility of life on Mars?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "220c05e9-61eb-4921-8dfe-7ae5ff830d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent updates from NASA suggest that the Perseverance rover has made intriguing discoveries on Mars that could be the clearest signs of ancient life so far. Scientists have found leopard spots on a rock sampled by the rover, which may have been made by ancient life. This finding has been published in a peer-reviewed paper in the journal Nature, although further study is needed to confirm these results. The analysis of the specimen collected by Perseverance raises the possibility of Martian microbes, but NASA scientists are not yet claiming to have found fossils of such life forms. \n",
      "\n",
      "For more detailed information, you can read the full articles on [The New York Times](https://www.nytimes.com/2025/09/10/science/mars-rock-nasa-perserverance.html) and [CNN](https://www.cnn.com/2025/09/10/science/nasa-mars-sapphire-falls-rock-sample).\n"
     ]
    }
   ],
   "source": [
    "print(response9[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2fdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
